{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin & Twitter\n",
    "\n",
    "Project on Data Mining by Bontenakel Lenny & Bels Senne.  \n",
    " *[Link to our github repository](https://github.com/snenenenenenene/btc-twitter-data-mining)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag\n",
    "\n",
    "Bestaat er een invloed tussen de activiteit rond Bitcoin op Twitter en de prijs van twitter? Zo ja, hoe groot is deze impact?\n",
    "\n",
    "Hiervoor zullen we het sentiment analyseren van elke tweet\n",
    "\t- algemeen sentiment\n",
    "\t- sentiment binnen een bepaalde periode (per maand mss?)\n",
    "\n",
    "Ook de activiteit van tweets binnen een bepaalde periode\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, desc, asc, udf, max as max_\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc\n",
    "import re\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import re\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import folium\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from geopy.geocoders import Nominatim\n",
    "from pattern.en import sentiment\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, desc, asc, udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# sc = SparkContext(\"local\").getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "### BITCOIN\n",
    "\n",
    " - Unix Timestamp - Date represented as epoc value\n",
    " - Date - date and time when the data point was collected\n",
    " - Symbol - Symbol of the currency\n",
    " - Open - Open value of the currency\n",
    " - High - Highest value of currency in the given minute\n",
    " - Low - Lowest value of currency in the given minute\n",
    " - Close - Close value of the currency in the given minute\n",
    " - Volume - Volume of the currency transacted in the given minute.\n",
    "\n",
    "### TWITTER\n",
    "\n",
    " - user_name    The name of the user, as theyâ€™ve defined it.\n",
    " - user_location    The user-defined location for this accountâ€™s profile.\n",
    " - user_description\tThe user-defined UTF-8 string describing their account.\n",
    " - user_created\tTime and date, when the account was created.\n",
    " - user_followers\tThe number of followers an account currently has.\n",
    " - user_friends\tThe number of friends a account currently has.\n",
    " - user_favourites\tThe number of favorites a account currently has\n",
    " - user_verified    When true, indicates that the user has a verified account\n",
    " - date UTC time and date when the Tweet was created\n",
    " - text The actual UTF-8 text of the Tweet\n",
    " - hashtags\tAll the other hashtags posted in the tweet along with #Bitcoin & #btc\n",
    " - source   Utility used to post the Tweet, Tweets from the Twitter website have a source value - web\n",
    " - is_retweet\tIndicates whether this Tweet has been Retweeted by the authenticating user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets\n",
    "\n",
    "We load tweet data from a dataset found on kaggle. A link to this dataset can be found in the README, provided in our *[github repository](https://github.com/snenenenenenene/btc-twitter-data-mining)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_schema = StructType([\n",
    "    StructField('user_name', StringType(), True),\n",
    "    StructField('user_location', StringType(), True),\n",
    "    StructField('user_description', StringType(), True),\n",
    "    StructField('user_created', StringType(), True),\n",
    "    StructField('user_followers', FloatType(), True),\n",
    "    StructField('user_friends', FloatType(), True),\n",
    "    StructField('user_favourites', FloatType(), True),\n",
    "    StructField('user_verified', BooleanType(), True),\n",
    "    StructField('date', StringType(), True),\n",
    "    StructField('text', StringType(), True),\n",
    "    StructField('hashtags', StringType(), True),\n",
    "    StructField('source', StringType(), True),\n",
    "    StructField('is_retweet', BooleanType(), True),\n",
    "])\n",
    "\n",
    "tweets_df = spark.read.csv(\n",
    "    \"./data/tweets.csv\",\n",
    "    header=True,\n",
    "    sep=',',\n",
    "    multiLine=True,\n",
    "    unescapedQuoteHandling=\"STOP_AT_CLOSING_QUOTE\",\n",
    "    schema=tweets_schema\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo finance data\n",
    "\n",
    "Now we will load the bitcoin financial data from yahoo finance using a python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_stock = yf.Ticker(\"BTC-USD\")\n",
    "end = datetime.datetime(2021, 11, 26)\n",
    "start = datetime.datetime(2021, 2, 5)\n",
    "\n",
    "btc_stock = btc_stock.history(start=start, end=end)\n",
    "btc_df = spark.createDataFrame(btc_stock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values\n",
    "\n",
    "Our dataset - now correctly loaded - shows that the amount of null values in the dataset is quite low. Except for the locations of users. This, however, is not due to a poor dataset, but due to these users not being willing to share their locations. Which should of course be respected and tolerated. Thus, there will be no actions taken to fill this data.  \n",
    "The red line indicates the total amount of rows present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.axhline(y=tweets_df.count(), label=\"Total amount of rows\")\n",
    "ax.bar_label(\n",
    "    ax.bar(\n",
    "        tweets_df.columns,\n",
    "        [tweets_df.where(col(l).isNull()).count() for l in tweets_df.columns]\n",
    "    )\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Columns\")\n",
    "ax.set_ylabel(\"# Null values\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing Data    Date|\n",
    "+-------+-------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def conv_to_int(val):\n",
    "    if isinstance(val, str):\n",
    "        return 0\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "\n",
    "conv_to_int_udf = udf(lambda x: conv_to_int(x), IntegerType())\n",
    "\n",
    "# tweets_df = tweets_df.withColumn(\"user_followers\", conv_to_int_udf(col(\"user_followers\")))\\\n",
    "#     .withColumn(\"user_friends\", conv_to_int_udf(col(\"user_friends\")))\\\n",
    "#     .withColumn(\"user_favourites\", conv_to_int_udf(col(\"user_favourites\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if (isinstance(text, str)):\n",
    "        text = text.replace(\"#\", \"\")\n",
    "        text = re.sub('\\\\n', '', text)\n",
    "        text = re.sub('https:\\/\\/\\S+', '', text)\n",
    "        return text\n",
    "    else:\n",
    "        return \"\"\n",
    "clean_text_udf = udf(lambda x: clean_text(x), StringType())\n",
    "\n",
    "\n",
    "\n",
    "tweets_df = tweets_df.withColumn(\"text\", clean_text_udf(col(\"text\"))).dropna(subset=[\"user_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating impact score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the hashtags array column \n",
    "Before we can generate the impact score, we need to generate an array of strings. This array represents the hashtags present within the tweet.\n",
    "Since the csv format - which we use to read in the data - does not support arrays in pyspark. We need to fix it after reading it in as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_hashtags_array(hashtags_arr_string):\n",
    "    try:\n",
    "        closing_bracket = hashtags_arr_string.index(']', 1)\n",
    "        subject = hashtags_arr_string[1 :closing_bracket]\n",
    "\n",
    "        result = subject.split(', ') if closing_bracket > 1 else []\n",
    "        result = ' '.join(result).replace(\"'\", \"\").split()\n",
    "\n",
    "        return result\n",
    "        \n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "fix_hashtags_array_udf = udf(lambda x: fix_hashtags_array(x), ArrayType(StringType()))\n",
    "\n",
    "tweets_df = tweets_df.fillna(\"[]\", subset=\"hashtags\").withColumn(\"hashtags\", fix_hashtags_array_udf(col(\"hashtags\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that is done. We can use this array to generate an impact score for every tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "\n",
    "def generate_impact_score(tweet):\n",
    "    coef_verified = 1.1 if tweet.user_verified else 1\n",
    "    coef_hashtags = 1 + (len(tweet.hashtags) / 20)\n",
    "    return ((tweet.user_followers + (tweet.user_friends / 4)) * coef_verified * coef_hashtags) / 100\n",
    "    \n",
    "generate_impact_score_udf = udf(lambda x: generate_impact_score(x), FloatType())\n",
    "\n",
    "tweets_df = tweets_df.withColumn(\"impact_score\", generate_impact_score_udf(struct([tweets_df[x] for x in tweets_df.columns])))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Date Dataframe\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_df = tweets_df.withColumn(\"date\", F.to_date(F.col(\"date\")))\n",
    "date_df = date_df.groupby(\"date\").count().dropna().sort(asc(\"date\")).filter(\n",
    "    (date_df.date > datetime.datetime(2020, 3, 20)) & (date_df.date < datetime.datetime.today()))\n",
    "\n",
    "counts_df = date_df\n",
    "\n",
    "def _get_next_dates(start_date: datetime.date, diff: int) -> List[datetime.date]:\n",
    "    return [start_date + datetime.timedelta(days=days) for days in range(1, diff)]\n",
    "\n",
    "def _get_fill_dates_df(df: DataFrame, date_column: str, group_columns: List[str], fill_column: str) -> DataFrame:\n",
    "    get_next_dates_udf = udf(_get_next_dates, ArrayType(DateType()))\n",
    "\n",
    "    window = Window.orderBy(*group_columns, date_column)\n",
    "\n",
    "    return df.withColumn(\"_diff\", F.datediff(F.lead(date_column, 1).over(window), date_column)).filter(col(\"_diff\") > 1).withColumn(\"_next_dates\", get_next_dates_udf(date_column, \"_diff\")).withColumn(fill_column, F.lit('')).withColumn(date_column, F.explode(\"_next_dates\")).drop(\"_diff\", \"_next_dates\")\n",
    "\n",
    "fill_df = _get_fill_dates_df(date_df, \"date\",[], \"count\")\n",
    "date_df = date_df.union(fill_df).sort(asc(col(\"date\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular users\n",
    "We will start separating data from the main dataframe, to create a new dataframe showing data about the used accounts.\n",
    "This way we can easily show what accounts are most followed and loved.\n",
    "However, user accounts are constantly changing. The amounts of followers, friends and favourites an accounts has rarely remains the same for long.\n",
    "These values rise and fall, therefore it would not be wise to simply select the instance with the max amount of followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df = tweets_df.groupBy('user_name').max('user_followers').withColumnRenamed('max(user_followers)', 'user_followers').sort(desc('user_followers'))\n",
    "\n",
    "x_rows = accounts_df.select('user_name').collect()\n",
    "y_rows = accounts_df.select('user_followers').collect()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "n = 20\n",
    "ax.barh(\n",
    "    [x.user_name for x in x_rows[:n]],\n",
    "    [y.user_followers for y in y_rows[:n]],\n",
    "    color='green',\n",
    "    label='tweets/ user'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where is Elon Musk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.where(tweets_df.user_name == \"Elon Musk\").show()\n",
    "# tweets_df.where(tweets_df.user_name == \"Reuters\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tweets / user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "user_volume = tweets_df.groupby(\"user_name\").count().withColumnRenamed(\"count\", \"user_count\").sort(desc(\"user_count\"))\n",
    "\n",
    "n = 10\n",
    "x_rows = user_volume.limit(n).select(\"user_name\").collect()\n",
    "y_rows = user_volume.limit(n).select(\"user_count\").collect()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.bar_label(\n",
    "    ax.barh([x.user_name for x in x_rows],\n",
    "           [y.user_count for y in y_rows],\n",
    "           label='tweets/ user')\n",
    ")\n",
    "\n",
    "ax.set_xlabel('# tweets')\n",
    "ax.set_ylabel('username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bitcoin Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_location = tweets_df.groupBy('user_location').count().sort(col(\"count\").desc()).show()\n",
    "geolocator = Nominatim(user_agent=\"example\")\n",
    "location_df = tweets_df.groupBy('user_location').count().filter(\"count >= 500\").where(\n",
    "    \"user_location not in ('Decentralized', 'Moon', 'ðŸ‡¦ðŸ‡º', 'Everywhere', 'Road Warrior', 'Mars', 'Cloud Engineer', 'Planet Earth', 'Earth', 'Blockchain', 'The Blockchain')\").sort(\n",
    "    col(\"count\").desc()).dropna().collect()\n",
    "\n",
    "\n",
    "def coords(location_string):\n",
    "    try:\n",
    "        location_obj = geolocator.geocode(location_string).raw\n",
    "        return (location_obj['lat'], location_obj['lon'])\n",
    "    except:\n",
    "        return (20, 20)\n",
    "\n",
    "\n",
    "locations = list(map(lambda r: [r['user_location'], r['count'], coords(r['user_location'])], location_df))\n",
    "map_tweets = folium.Map(location=[51,10], zoom_start=2)\n",
    "\n",
    "for location_name, count, location_coords in locations:\n",
    "    folium.Circle(location=location_coords,\n",
    "                  popup=f\"{location_name}: {count}\",\n",
    "                  radius=count * 50,\n",
    "                  color=\"crimson\",\n",
    "                  fill_color=\"crimson\",\n",
    "                  tooltip=count).add_to(map_tweets)\n",
    "map_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X FOR BTC VOLUME\n",
    "dates = date_df.select(\"date\").collect()\n",
    "x = list(map(lambda r: (r['date']), dates))\n",
    "\n",
    "# X FOR COUNTS\n",
    "counts_dates = counts_df.select(\"date\").collect()\n",
    "counts_x = list(map(lambda r: (r['date']), counts_dates))\n",
    "\n",
    "# Y/COUNT OF TWEETS\n",
    "y_rows = counts_df.select(\"count\").collect()\n",
    "tweets_y = list(map(lambda r: r['count'], y_rows))\n",
    "\n",
    "# Y FOR BTC VOLUME\n",
    "y_rows = btc_df.select(\"Open\").collect()\n",
    "btc_y = list(map(lambda r: float(r['Open']), y_rows))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.plot(counts_dates, tweets_y, color='blue', label='Tweet Volume')\n",
    "# ax.set_yscale('log')\n",
    "ax.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x,btc_y, color='red', label='BTC Value')\n",
    "# ax2.set_yscale('log')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2 , labels + labels2, loc=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Here we will analyse the sentiments....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweets_df.select(\"text\").collect()\n",
    "sentiments = [(x.text, *sentiment(x.text)) for x in tweet_text]\n",
    "\n",
    "sentiment_schema = [\"text\", \"polarity\", \"subjectivity\"]\n",
    "sentiments_df = spark.createDataFrame(\n",
    "    data=sentiments,\n",
    "    schema=sentiment_schema\n",
    ")\n",
    "\n",
    "sentiments_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the sake of not cluttering the chart with futile words such as 'a', 'in' or 'and' we left out the aforementioned ones as well as a short - yet cherry-picked - list of others."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_occurance = tweets_df.withColumn('word', F.explode(F.split(F.col('text'), ' '))).groupBy('word').count().sort('count', ascending=False).where(\n",
    "    \"word not in (' ', '', 'the', 'a', 'to', 'and', 'a', 'in', 'of', 'for', 'you', 'will', 'be', 'on', 'this', 'i', 'The', 'are', 'at', 'it', 'I')\").limit(100)\n",
    "\n",
    "twitter_mask = np.array(Image.open('twitter.jpeg'))\n",
    "freqs = {r.asDict()['word'] : r.asDict()['count'] for r in word_occurance.collect()}\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", mask=twitter_mask).generate_from_frequencies(freqs)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hashtags_occurance = tweets_df.withColumn('hashtag', F.explode(col('hashtags'))).groupBy('hashtag').count().sort('count', ascending=False).limit(20)\n",
    "\n",
    "hashtags_occurance = tweets_df.select(\"hashtags\").withColumn(\"hashtag\", F.explode(col('hashtags'))).groupBy('hashtag').count().sort(desc('count')).limit(20)\n",
    "\n",
    "hashtags_occurance.show()\n",
    "\n",
    "\n",
    "hashtag_rows = hashtags_occurance.select(\"hashtag\").collect()\n",
    "x = list(map(lambda r: (r['hashtag']), hashtag_rows))\n",
    "\n",
    "y_rows = hashtags_occurance.select(\"count\").collect()\n",
    "y = list(map(lambda r: int(r['count']), y_rows))\n",
    "\n",
    "plt.subplots(figsize=(16, 8))\n",
    "plt.barh(x,y, color='orange', label='Volume')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "950bcc60cdb4806130dd1b0626e927a3ecaad35b0daba1c028607da664f6fb11"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}